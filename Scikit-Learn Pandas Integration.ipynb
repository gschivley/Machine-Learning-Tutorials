{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-Learn's new integration with Pandas\n",
    "\n",
    "Scikit-Learn will make one of its biggest upgrades in recent years with its mammoth version 0.20 release. For those that like to work with Pandas to do exploratory data analysis and then move to Scikit-Learn then this will likely mean a huge improvement to your workflow.\n",
    "\n",
    "All of Scikit-Learn machine learning models require the input to be a two dimensional numpy array of numeric values. No string values are allowed. Although there are many methods to encode string variables as numeric, scikit-learn never provided a canonical way to handle this very common occurrence.\n",
    "\n",
    "This lead to numerous tutorials handling string columns in a variety of different ways. People were turning to Pandas `get_dummies` function, creating their own custom estimators, or even developing entire packages, such as [sklearn-pandas][1], to support this trouble spot. This lack of standardization made for a painful experience for those wanting to build machine learning models with string columns.\n",
    "\n",
    "Furthermore, there was poor support for making transformations to specific columns and not to the entire array. For instance, if you wanted to standardize continuous features but not categorical features.\n",
    "\n",
    "# Introducing `ColumnTransformer` and the upgraded `OneHotEncoder`\n",
    "With the upgrade to version 0.20, many workflows from Pandas to Scikit-Learn should start looking more similar. The `ColumnTransformer` estimator will apply a transformation to a specific subset of columns of your Pandas DataFrame (or array).\n",
    "\n",
    "The `OneHotEncoder` estimator is not new but has been upgraded to encode string columns. Before, it only encoded columns containing numeric categorical data.\n",
    "\n",
    "Let's see how these new additions work to handle string columns in a Pandas DataFrame.\n",
    "\n",
    "# Kaggle Housing Dataset\n",
    "The [Housing Prices: Advanced Regression Techniques][2] is a beginners machine learning competition permanently ongoing from Kaggle. The goal is to predict housing prices given about 80 features. There are a mix of continuous and categorical columns. Download the data - I suggest using the [command line tool API][3].\n",
    "\n",
    "### Inspect the data\n",
    "Let's read in our DataFrame and output the first few rows.\n",
    "\n",
    "[1]: https://github.com/scikit-learn-contrib/sklearn-pandas\n",
    "[2]: https://www.kaggle.com/c/house-prices-advanced-regression-techniques\n",
    "[3]: https://github.com/Kaggle/kaggle-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities    ...     PoolArea PoolQC Fence MiscFeature MiscVal  \\\n",
       "0         Lvl    AllPub    ...            0    NaN   NaN         NaN       0   \n",
       "1         Lvl    AllPub    ...            0    NaN   NaN         NaN       0   \n",
       "2         Lvl    AllPub    ...            0    NaN   NaN         NaN       0   \n",
       "3         Lvl    AllPub    ...            0    NaN   NaN         NaN       0   \n",
       "4         Lvl    AllPub    ...            0    NaN   NaN         NaN       0   \n",
       "\n",
       "  MoSold YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0      2   2008        WD         Normal     208500  \n",
       "1      5   2007        WD         Normal     181500  \n",
       "2      9   2008        WD         Normal     223500  \n",
       "3      2   2006        WD        Abnorml     140000  \n",
       "4     12   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('data/housing/train.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 81)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove the target variable from the training set\n",
    "The target variable is `SalePrice` which we remove and assign as an array to its own variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train.pop('SalePrice').values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding a single string column\n",
    "To start off, let's encode a single string column, `HouseStyle`, which has values for the exterior of the house. Let's output the unique counts of each string value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1Story    726\n",
       "2Story    445\n",
       "1.5Fin    154\n",
       "SLvl       65\n",
       "SFoyer     37\n",
       "1.5Unf     14\n",
       "2.5Unf     11\n",
       "2.5Fin      8\n",
       "Name: HouseStyle, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vc = train['HouseStyle'].value_counts()\n",
    "vc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 8 unique values in this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-Learn Gotcha - Must have 2D data\n",
    "Most Scikit-Learn estimator require that data be strictly 2-dimensional. If we select the column above as `train['HouseStyle']`, this technically creates a Pandas Series which is a single dimension of data. We can force Pandas to create a one-column DataFrame, by passing a single-item list to the brackets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hs_train = train[['HouseStyle']].copy()\n",
    "hs_train.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import, Instantiate, Fit - The three-step process for each estimator\n",
    "The scikit-learn API is consistent for all estimators and uses a three-step process to train or fit the data. \n",
    "\n",
    "1. Import the estimator we want from the module its located in\n",
    "1. Instantiate the estimator possibly changing its defaults\n",
    "1. Fit the estimator to the data. Possibly transform the data to its new space if need be.\n",
    "\n",
    "Below, we import `OneHotEncoder`, instantiate it and ensure that we get a dense (and not sparse) array returned and then encode our single column with the `fit_transform` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder(sparse=False)\n",
    "hs_train_transformed = ohe.fit_transform(hs_train)\n",
    "hs_train_transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, it has encoded each unique value as its own binary column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hs_train_transformed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We have a NumPy array. Where are the column names?\n",
    "Notice that our output is a NumPy array and not a Pandas DataFrame. Scikit-Learn was not originally built to be directly integrated with Pandas. All Pandas objects are converted to NumPy arrays internally and NumPy arrays are always returned after a transformation.\n",
    "\n",
    "We can still get our column name from the `OneHotEncoder` object through its `get_feature_names` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['x0_1.5Fin', 'x0_1.5Unf', 'x0_1Story', 'x0_2.5Fin', 'x0_2.5Unf',\n",
       "       'x0_2Story', 'x0_SFoyer', 'x0_SLvl'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = ohe.get_feature_names()\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verifying our first row of data is correct\n",
    "It's good to verify that our estimator is properly working. Let's look at the first row of encoded data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 0.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row0 = hs_train_transformed[0]\n",
    "row0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This encodes the 6th value in the array as 1. Let's use boolean indexing to reveal the feature name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['x0_2Story'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names[row0 == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's verify that the first value in our original DataFrame column is the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2Story'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hs_train.values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use `inverse_transform` to automate this\n",
    "Just like most transformer objects, there is an `inverse_transform` method that will get you back your original data. Here we must wrap `row0` in a list to make it a 2D array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['2Story']], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe.inverse_transform([row0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can verify all values by inverting the entire transformed array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['2Story'],\n",
       "       ['1Story'],\n",
       "       ['2Story'],\n",
       "       ...,\n",
       "       ['2Story'],\n",
       "       ['1Story'],\n",
       "       ['1Story']], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hs_inv = ohe.inverse_transform(hs_train_transformed)\n",
    "hs_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_equal(hs_inv, hs_train.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying transformation to the test set\n",
    "Whatever transformation we do to our training set, we must apply to our test set. Let's read in the test set and get the same column and apply our transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1461</td>\n",
       "      <td>20</td>\n",
       "      <td>RH</td>\n",
       "      <td>80.0</td>\n",
       "      <td>11622</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1462</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>81.0</td>\n",
       "      <td>14267</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gar2</td>\n",
       "      <td>12500</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1463</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>74.0</td>\n",
       "      <td>13830</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1464</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>78.0</td>\n",
       "      <td>9978</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1465</td>\n",
       "      <td>120</td>\n",
       "      <td>RL</td>\n",
       "      <td>43.0</td>\n",
       "      <td>5005</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>HLS</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0  1461          20       RH         80.0    11622   Pave   NaN      Reg   \n",
       "1  1462          20       RL         81.0    14267   Pave   NaN      IR1   \n",
       "2  1463          60       RL         74.0    13830   Pave   NaN      IR1   \n",
       "3  1464          60       RL         78.0     9978   Pave   NaN      IR1   \n",
       "4  1465         120       RL         43.0     5005   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities      ...       ScreenPorch PoolArea PoolQC  Fence  \\\n",
       "0         Lvl    AllPub      ...               120        0    NaN  MnPrv   \n",
       "1         Lvl    AllPub      ...                 0        0    NaN    NaN   \n",
       "2         Lvl    AllPub      ...                 0        0    NaN  MnPrv   \n",
       "3         Lvl    AllPub      ...                 0        0    NaN    NaN   \n",
       "4         HLS    AllPub      ...               144        0    NaN    NaN   \n",
       "\n",
       "  MiscFeature MiscVal MoSold  YrSold  SaleType  SaleCondition  \n",
       "0         NaN       0      6    2010        WD         Normal  \n",
       "1        Gar2   12500      6    2010        WD         Normal  \n",
       "2         NaN       0      3    2010        WD         Normal  \n",
       "3         NaN       0      6    2010        WD         Normal  \n",
       "4         NaN       0      1    2010        WD         Normal  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('data/housing/test.csv')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs_test = test[['HouseStyle']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hs_test_transformed = ohe.transform(hs_test)\n",
    "hs_test_transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should again get 8 columns and we do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1459, 8)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hs_test_transformed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trouble area #1 - Categories unique to the test set\n",
    "What happens if we have a home with a house style that is unique to just the test set? Say something like `3Story`. Let's change the first value of the house styles and see what the default is from Scikit-Learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HouseStyle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3Story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1Story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2Story</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  HouseStyle\n",
       "0     3Story\n",
       "1     1Story\n",
       "2     2Story"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hs_test = test[['HouseStyle']].copy()\n",
    "hs_test.iloc[0, 0] = '3Story'\n",
    "hs_test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found unknown categories ['3Story'] in column 0 during transform",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-2d33a65e4f12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mohe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhs_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    573\u001b[0m                                        copy=True)\n\u001b[1;32m    574\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py\u001b[0m in \u001b[0;36m_transform_new\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    535\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m         \u001b[0mX_int\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle_unknown\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_unknown\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py\u001b[0m in \u001b[0;36m_transform\u001b[0;34m(self, X, handle_unknown)\u001b[0m\n\u001b[1;32m     95\u001b[0m                     msg = (\"Found unknown categories {0} in column {1}\"\n\u001b[1;32m     96\u001b[0m                            \" during transform\".format(diff, i))\n\u001b[0;32m---> 97\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                     \u001b[0;31m# Set the problematic rows to an acceptable value and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found unknown categories ['3Story'] in column 0 during transform"
     ]
    }
   ],
   "source": [
    "ohe.transform(hs_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error: Unknown Category\n",
    "By default, our encoder will produce an error. This is likely what we want as we need to know if there are unique strings in the test set. If you do have this problem then there could be something much deeper that needs investigating. For now, we will ignore this problem and encode this row as all 0's by setting the `handle_unknown` parameter to 'ignore' upon instantiation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(categorical_features=None, categories=None,\n",
       "       dtype=<class 'numpy.float64'>, handle_unknown='ignore',\n",
       "       n_values=None, sparse=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "ohe.fit(hs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hs_test_transformed = ohe.transform(hs_test)\n",
    "hs_test_transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's verify that the first row is all 0's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hs_test_transformed[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trouble area #2 - Missing Values in test set\n",
    "If you have missing values in your test set (NaN or None), then these will be ignored as long as `handle_unknown` is set to 'ignore'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HouseStyle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2Story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2Story</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  HouseStyle\n",
       "0        NaN\n",
       "1       None\n",
       "2     2Story\n",
       "3     2Story"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hs_test = test[['HouseStyle']].copy()\n",
    "hs_test.iloc[0, 0] = np.nan\n",
    "hs_test.iloc[1, 0] = None\n",
    "hs_test.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hs_test_transformed = ohe.transform(hs_test)\n",
    "hs_test_transformed[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trouble area #3 - Missing Values in training set\n",
    "Missing values in the training set is more of an issue. As of now, the `OneHotEncoder` estimator cannot fit with missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HouseStyle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1Story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2Story</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  HouseStyle\n",
       "0        NaN\n",
       "1     1Story\n",
       "2     2Story"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hs_train = hs_train.copy()\n",
    "hs_train.iloc[0, 0] = np.nan\n",
    "hs_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'str' and 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-6b0498cdc461>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mohe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOneHotEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle_unknown\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mohe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhs_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    483\u001b[0m                 self._categorical_features, copy=True)\n\u001b[1;32m    484\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 485\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_legacy_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle_unknown\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_unknown\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    405\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, handle_unknown)\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mXi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_categories\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'auto'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m                 \u001b[0mcats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m                 \u001b[0mcats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_categories\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py\u001b[0m in \u001b[0;36m_encode\u001b[0;34m(values, uniques, encode)\u001b[0m\n\u001b[1;32m    106\u001b[0m     \"\"\"\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_encode_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muniques\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_encode_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muniques\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py\u001b[0m in \u001b[0;36m_encode_python\u001b[0;34m(values, uniques, encode)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;31m# only used in _encode below, see docstring there for details\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muniques\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'str' and 'float'"
     ]
    }
   ],
   "source": [
    "ohe = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "ohe.fit_transform(hs_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would be nice if there was an option to ignore them like what happens when transforming the test set above. But this doesn't exist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Must impute missing values\n",
    "For now, we must impute the missing values. The old `Imputer` from the preprocessing module got deprecated. A new module, `impute`, was formed in its place, with a new estimator `SimpleImputer` and a new strategy, 'constant'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['MISSING'],\n",
       "       ['1Story'],\n",
       "       ['2Story'],\n",
       "       ...,\n",
       "       ['2Story'],\n",
       "       ['1Story'],\n",
       "       ['1Story']], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hs_train = train[['HouseStyle']].copy()\n",
    "hs_train.iloc[0, 0] = np.nan\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "si = SimpleImputer(strategy='constant', fill_value='MISSING')\n",
    "hs_train_imputed = si.fit_transform(hs_train)\n",
    "hs_train_imputed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here, we can then"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hs_train_transformed = ohe.fit_transform(hs_train_imputed)\n",
    "hs_train_transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice, that we now have an extra column and and an extra feature name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 9)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hs_train_transformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['x0_1.5Fin', 'x0_1.5Unf', 'x0_1Story', 'x0_2.5Fin', 'x0_2.5Unf',\n",
       "       'x0_2Story', 'x0_MISSING', 'x0_SFoyer', 'x0_SLvl'], dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply both transformations to test set\n",
    "We can manually apply each of the two steps above in order like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs_test = test[['HouseStyle']].copy()\n",
    "hs_test.iloc[0, 0] = 'reasdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1459, 9)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hs_test_imputed = si.transform(hs_test)\n",
    "hs_test_transformed = ohe.transform(hs_test_imputed)\n",
    "hs_test_transformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['x0_1.5Fin', 'x0_1.5Unf', 'x0_1Story', 'x0_2.5Fin', 'x0_2.5Unf',\n",
       "       'x0_2Story', 'x0_MISSING', 'x0_SFoyer', 'x0_SLvl'], dtype=object)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use a `Pipeline` instead\n",
    "Scikit-Learn provides a Pipeline transformer and estimator that takes a list of transformations and applies them in succession. You can also run a machine learning model as the final estimator. Here we simply impute and encode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each step is a two-item tuple consisting of a string that labels the step and the instantiated estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "si_step = ('si', SimpleImputer(strategy='constant', fill_value='MISSING'))\n",
    "ohe_step = ('ohee', OneHotEncoder(sparse=False, handle_unknown='ignore'))\n",
    "steps = [si_step, ohe_step]\n",
    "\n",
    "pipe = Pipeline(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "hs_train = train[['HouseStyle']].copy()\n",
    "hs_train.iloc[0, 0] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit_transform(hs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hs_test = test[['HouseStyle']].copy()\n",
    "pipe.transform(hs_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple String Columns\n",
    "Encoding multiple string columns is not a problem. Select the columns you want and then pass the new DataFrame through the pipeline again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RoofMatl</th>\n",
       "      <th>HouseStyle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CompShg</td>\n",
       "      <td>2Story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CompShg</td>\n",
       "      <td>1Story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CompShg</td>\n",
       "      <td>2Story</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  RoofMatl HouseStyle\n",
       "0  CompShg     2Story\n",
       "1  CompShg     1Story\n",
       "2  CompShg     2Story"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string_cols = ['RoofMatl', 'HouseStyle']\n",
    "string_train = train[string_cols]\n",
    "string_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., ..., 1., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0., ..., 1., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "si_step = ('si', SimpleImputer(strategy='constant', fill_value='MISSING'))\n",
    "ohe_step = ('ohe', OneHotEncoder(sparse=False, handle_unknown='ignore'))\n",
    "steps = [si_step, ohe_step]\n",
    "\n",
    "pipe = Pipeline(steps)\n",
    "pipe.fit_transform(string_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get individual pieces of the pipeline\n",
    "It is possible to get each individual transformer through its name. In this instance, we get the one-hot encoder so that we can output the feature names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['x0_ClyTile', 'x0_CompShg', 'x0_Membran', 'x0_Metal', 'x0_Roll',\n",
       "       'x0_Tar&Grv', 'x0_WdShake', 'x0_WdShngl', 'x1_1.5Fin', 'x1_1.5Unf',\n",
       "       'x1_1Story', 'x1_2.5Fin', 'x1_2.5Unf', 'x1_2Story', 'x1_SFoyer',\n",
       "       'x1_SLvl'], dtype=object)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe = pipe.named_steps['ohe']\n",
    "ohe.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use the new `ColumnTransformer` to choose columns\n",
    "The brand new transformer `ColumnTransformer` (part of the new `compose` module) allows you to choose which columns get which transformations. Categorical columns will almost always need separate transformations than continuous columns.\n",
    "\n",
    "The `ColumnTransformer` is currently experimental, meaning that its functionality can change in the future. There also appears to be a few bugs with it as well. I even [found one][1] while writing this tutorial.\n",
    "\n",
    "The `ColumnTransformer` works similarly to `Pipeline` in that it takes a list of tuples, but instead of two items, each tuple is three items in length and will look like this:\n",
    "```\n",
    "('name1', SomeTransformer(parameters), columns)\n",
    "```\n",
    "\n",
    "Where `columns` is a list of the DataFrame columns that you want to transform during that step. You can also choose the columns with integer indexes, a boolean array, or even a function.\n",
    "\n",
    "### Pass a `Pipeline` to the `ColumnTransformer`\n",
    "We can even pass a pipeline of many transformations to the column transformer, and in fact there is a bug that forces us do just that.\n",
    "\n",
    "Below, we reproduce the above imputing and encoding using the ColumnTransformer.\n",
    "\n",
    "[1]: https://github.com/scikit-learn/scikit-learn/issues/11969"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "si_step = ('si', SimpleImputer(strategy='constant', fill_value='MISSING'))\n",
    "ohe_step = ('ohe', OneHotEncoder(sparse=False, handle_unknown='ignore'))\n",
    "steps = [si_step, ohe_step]\n",
    "\n",
    "cat_pipe = Pipeline(steps)\n",
    "cat_cols = ['RoofMatl', 'HouseStyle']\n",
    "transformers = [('cat', cat_pipe, cat_cols)]\n",
    "\n",
    "ct = ColumnTransformer(transformers=transformers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., ..., 1., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0., ..., 1., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = ct.fit_transform(train)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 16)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now transform our test set in the same manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = ct.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1459, 16)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieving the feature names\n",
    "We have to do a little searching to get the feature names. We use the names attribute of the transformers. First, we select our transformer (there is only one here - a pipeline named cat)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = ct.named_transformers_['cat']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then from this pipeline we select the one-hot encoder object and finally get the feature names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['x0_ClyTile', 'x0_CompShg', 'x0_Membran', 'x0_Metal', 'x0_Roll',\n",
       "       'x0_Tar&Grv', 'x0_WdShake', 'x0_WdShngl', 'x1_1.5Fin', 'x1_1.5Unf',\n",
       "       'x1_1Story', 'x1_2.5Fin', 'x1_2.5Unf', 'x1_2Story', 'x1_SFoyer',\n",
       "       'x1_SLvl'], dtype=object)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe = pl.named_steps['ohe']\n",
    "ohe.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforming the numeric columns\n",
    "The numeric columns will need a different set of transformations. Instead of imputing missing values with a constant, the median or mean is often chosen. And instead of encoding the values, we usually standardize them by subtracting the mean of each column and dividing by the standard deviation. This helps many models like ridge regression produce a better fit.\n",
    "\n",
    "## Usually all the numeric columns\n",
    "We can select all of the numeric columns by first finding the dtypes of each column and then testing whether the `kind` attribute is 'O'. See the [NumPy docs][1] for more on the `kind` attribute.\n",
    "\n",
    "[1]: https://docs.scipy.org/doc/numpy/reference/generated/numpy.dtype.kind.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id               int64\n",
       "MSSubClass       int64\n",
       "MSZoning        object\n",
       "LotFrontage    float64\n",
       "LotArea          int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.dtypes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['i', 'i', 'O', 'f', 'i', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O',\n",
       "       'O', 'O', 'O', 'O', 'i', 'i', 'i', 'i', 'O', 'O', 'O', 'O', 'O',\n",
       "       'f', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'i', 'O', 'i', 'i', 'i',\n",
       "       'O', 'O', 'O', 'O', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i',\n",
       "       'i', 'O', 'i', 'O', 'i', 'O', 'O', 'f', 'O', 'i', 'i', 'O', 'O',\n",
       "       'O', 'i', 'i', 'i', 'i', 'i', 'i', 'O', 'O', 'O', 'i', 'i', 'i',\n",
       "       'O', 'O'], dtype='<U1')"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kinds = np.array([dt.kind for dt in train.dtypes])\n",
    "kinds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Id', 'MSSubClass', 'LotFrontage', 'LotArea', 'OverallQual',\n",
       "       'OverallCond', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea',\n",
       "       'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF',\n",
       "       '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'BsmtFullBath',\n",
       "       'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr',\n",
       "       'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces', 'GarageYrBlt',\n",
       "       'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF',\n",
       "       'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal',\n",
       "       'MoSold', 'YrSold'], dtype=object)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_cols = train.columns[kinds != 'O'].values\n",
    "numeric_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have our numeric column names, we can use the same steps as above with help from the `ColumnTransformer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "si_step = ('si', SimpleImputer(strategy='median'))\n",
    "ss_step = ('ss', StandardScaler())\n",
    "steps = [si_step, ss_step]\n",
    "\n",
    "num_pipe = Pipeline(steps)\n",
    "transformers = [('num', num_pipe, numeric_cols)]\n",
    "\n",
    "ct = ColumnTransformer(transformers=transformers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.73086488,  0.07337496, -0.22087509, ..., -0.08768781,\n",
       "        -1.5991111 ,  0.13877749],\n",
       "       [-1.7284922 , -0.87256276,  0.46031974, ..., -0.08768781,\n",
       "        -0.48911005, -0.61443862],\n",
       "       [-1.72611953,  0.07337496, -0.08463612, ..., -0.08768781,\n",
       "         0.99089135,  0.13877749],\n",
       "       ...,\n",
       "       [ 1.72611953,  0.30985939, -0.1754621 , ...,  4.95311151,\n",
       "        -0.48911005,  1.64520971],\n",
       "       [ 1.7284922 , -0.87256276, -0.08463612, ..., -0.08768781,\n",
       "        -0.8591104 ,  1.64520971],\n",
       "       [ 1.73086488, -0.87256276,  0.23325479, ..., -0.08768781,\n",
       "        -0.1191097 ,  0.13877749]])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = ct.fit_transform(train)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 37)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining both categorical and numerical column transformations\n",
    "We can apply separate transformations to each secton of our DataFrame and `ColumnTransforer` will automatically concatenate our results together. Below we create a pipeline for both categorical and numerical columns and then use the `ColumnTransformer` to independently transform them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 305)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_columns = train.columns.values\n",
    "kinds = np.array([dt.kind for dt in train.dtypes])\n",
    "is_numeric = kinds != 'O'\n",
    "numeric_cols = all_columns[is_numeric]\n",
    "cat_cols = all_columns[~is_numeric]\n",
    "\n",
    "si_cat_step = ('si', SimpleImputer(strategy='constant', fill_value='MISSING'))\n",
    "ohe_step = ('ohe', OneHotEncoder(sparse=False, handle_unknown='ignore'))\n",
    "cat_steps = [si_cat_step, ohe_step]\n",
    "cat_pipe = Pipeline(cat_steps)\n",
    "\n",
    "si_num_step = ('si', SimpleImputer(strategy='median'))\n",
    "ss_step = ('ss', StandardScaler())\n",
    "num_steps = [si_num_step, ss_step]\n",
    "num_pipe = Pipeline(num_steps)\n",
    "\n",
    "transformers = [('cat', cat_pipe, cat_cols),\n",
    "                ('num', num_pipe, numeric_cols)]\n",
    "\n",
    "ct = ColumnTransformer(transformers=transformers)\n",
    "\n",
    "X = ct.fit_transform(train)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "We can create one final pipeline and add a machine learning model as the final estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_pipe = Pipeline([('transform', ct), ('ridge', Ridge())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('transform', ColumnTransformer(n_jobs=None, remainder='drop', sparse_threshold=0.3,\n",
       "         transformer_weights=None,\n",
       "         transformers=[('cat', Pipeline(memory=None,\n",
       "     steps=[('si', SimpleImputer(copy=True, fill_value='MISSING', missing_values=nan,\n",
       "       strategy='constant', verbos...it_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001))])"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_pipe.fit(train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "kf = KFold(n_splits=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8119226710668714"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(ml_pipe, train, y, cv=kf).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting parameters when Grid Searching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'transform__num__si__strategy': ['mean', 'median'],\n",
    "    'ridge__alpha': [.001, 0.1, 1.0, 10, 100],\n",
    "}\n",
    "gs = GridSearchCV(ml_pipe, param_grid, cv=kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=True),\n",
       "       error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('transform', ColumnTransformer(n_jobs=None, remainder='drop', sparse_threshold=0.3,\n",
       "         transformer_weights=None,\n",
       "         transformers=[('cat', Pipeline(memory=None,\n",
       "     steps=[('si', SimpleImputer(copy=True, fill_value='MISSING', missing_values=nan,\n",
       "       strategy='constant', verbos...it_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001))]),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'transform__num__si__strategy': ['mean', 'median'], 'ridge__alpha': [0.001, 0.1, 1.0, 10, 100]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.fit(train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ridge__alpha': 10, 'transform__num__si__strategy': 'mean'}"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Ted/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/Ted/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/Ted/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/Ted/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/Ted/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/Ted/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/Users/Ted/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_ridge__alpha</th>\n",
       "      <th>param_transform__num__si__strategy</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.034049</td>\n",
       "      <td>0.002207</td>\n",
       "      <td>0.009171</td>\n",
       "      <td>0.001338</td>\n",
       "      <td>0.001</td>\n",
       "      <td>mean</td>\n",
       "      <td>{'ridge__alpha': 0.001, 'transform__num__si__s...</td>\n",
       "      <td>0.901581</td>\n",
       "      <td>0.856938</td>\n",
       "      <td>0.893413</td>\n",
       "      <td>...</td>\n",
       "      <td>0.564308</td>\n",
       "      <td>0.544383</td>\n",
       "      <td>10</td>\n",
       "      <td>0.935158</td>\n",
       "      <td>0.939936</td>\n",
       "      <td>0.929458</td>\n",
       "      <td>0.945877</td>\n",
       "      <td>0.937442</td>\n",
       "      <td>0.937574</td>\n",
       "      <td>0.005408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.034064</td>\n",
       "      <td>0.000914</td>\n",
       "      <td>0.007842</td>\n",
       "      <td>0.000284</td>\n",
       "      <td>0.001</td>\n",
       "      <td>median</td>\n",
       "      <td>{'ridge__alpha': 0.001, 'transform__num__si__s...</td>\n",
       "      <td>0.901578</td>\n",
       "      <td>0.856964</td>\n",
       "      <td>0.893429</td>\n",
       "      <td>...</td>\n",
       "      <td>0.564316</td>\n",
       "      <td>0.544383</td>\n",
       "      <td>9</td>\n",
       "      <td>0.935158</td>\n",
       "      <td>0.939935</td>\n",
       "      <td>0.929453</td>\n",
       "      <td>0.945877</td>\n",
       "      <td>0.937442</td>\n",
       "      <td>0.937573</td>\n",
       "      <td>0.005410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.030157</td>\n",
       "      <td>0.000369</td>\n",
       "      <td>0.007588</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.1</td>\n",
       "      <td>mean</td>\n",
       "      <td>{'ridge__alpha': 0.1, 'transform__num__si__str...</td>\n",
       "      <td>0.899387</td>\n",
       "      <td>0.854853</td>\n",
       "      <td>0.895557</td>\n",
       "      <td>...</td>\n",
       "      <td>0.800789</td>\n",
       "      <td>0.103319</td>\n",
       "      <td>8</td>\n",
       "      <td>0.934084</td>\n",
       "      <td>0.938858</td>\n",
       "      <td>0.928206</td>\n",
       "      <td>0.944976</td>\n",
       "      <td>0.935014</td>\n",
       "      <td>0.936228</td>\n",
       "      <td>0.005548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.034269</td>\n",
       "      <td>0.002525</td>\n",
       "      <td>0.007771</td>\n",
       "      <td>0.000425</td>\n",
       "      <td>0.1</td>\n",
       "      <td>median</td>\n",
       "      <td>{'ridge__alpha': 0.1, 'transform__num__si__str...</td>\n",
       "      <td>0.899382</td>\n",
       "      <td>0.854888</td>\n",
       "      <td>0.895568</td>\n",
       "      <td>...</td>\n",
       "      <td>0.800795</td>\n",
       "      <td>0.103326</td>\n",
       "      <td>7</td>\n",
       "      <td>0.934083</td>\n",
       "      <td>0.938857</td>\n",
       "      <td>0.928201</td>\n",
       "      <td>0.944977</td>\n",
       "      <td>0.935014</td>\n",
       "      <td>0.936227</td>\n",
       "      <td>0.005549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.032000</td>\n",
       "      <td>0.001501</td>\n",
       "      <td>0.008202</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>1</td>\n",
       "      <td>mean</td>\n",
       "      <td>{'ridge__alpha': 1.0, 'transform__num__si__str...</td>\n",
       "      <td>0.894367</td>\n",
       "      <td>0.844483</td>\n",
       "      <td>0.884532</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806715</td>\n",
       "      <td>0.091847</td>\n",
       "      <td>4</td>\n",
       "      <td>0.922084</td>\n",
       "      <td>0.928361</td>\n",
       "      <td>0.915705</td>\n",
       "      <td>0.933772</td>\n",
       "      <td>0.931898</td>\n",
       "      <td>0.926364</td>\n",
       "      <td>0.006655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.032464</td>\n",
       "      <td>0.000531</td>\n",
       "      <td>0.007599</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>1</td>\n",
       "      <td>median</td>\n",
       "      <td>{'ridge__alpha': 1.0, 'transform__num__si__str...</td>\n",
       "      <td>0.894384</td>\n",
       "      <td>0.844506</td>\n",
       "      <td>0.884530</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806720</td>\n",
       "      <td>0.091857</td>\n",
       "      <td>3</td>\n",
       "      <td>0.922086</td>\n",
       "      <td>0.928360</td>\n",
       "      <td>0.915707</td>\n",
       "      <td>0.933771</td>\n",
       "      <td>0.931898</td>\n",
       "      <td>0.926364</td>\n",
       "      <td>0.006654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.030082</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>0.007481</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>10</td>\n",
       "      <td>mean</td>\n",
       "      <td>{'ridge__alpha': 10, 'transform__num__si__stra...</td>\n",
       "      <td>0.893760</td>\n",
       "      <td>0.840727</td>\n",
       "      <td>0.863183</td>\n",
       "      <td>...</td>\n",
       "      <td>0.811317</td>\n",
       "      <td>0.083677</td>\n",
       "      <td>1</td>\n",
       "      <td>0.897985</td>\n",
       "      <td>0.906401</td>\n",
       "      <td>0.896868</td>\n",
       "      <td>0.909821</td>\n",
       "      <td>0.919559</td>\n",
       "      <td>0.906127</td>\n",
       "      <td>0.008321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.032869</td>\n",
       "      <td>0.000938</td>\n",
       "      <td>0.007679</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>10</td>\n",
       "      <td>median</td>\n",
       "      <td>{'ridge__alpha': 10, 'transform__num__si__stra...</td>\n",
       "      <td>0.893885</td>\n",
       "      <td>0.840658</td>\n",
       "      <td>0.863156</td>\n",
       "      <td>...</td>\n",
       "      <td>0.811305</td>\n",
       "      <td>0.083714</td>\n",
       "      <td>2</td>\n",
       "      <td>0.897979</td>\n",
       "      <td>0.906406</td>\n",
       "      <td>0.896882</td>\n",
       "      <td>0.909821</td>\n",
       "      <td>0.919561</td>\n",
       "      <td>0.906130</td>\n",
       "      <td>0.008319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.030034</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>0.007594</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>100</td>\n",
       "      <td>mean</td>\n",
       "      <td>{'ridge__alpha': 100, 'transform__num__si__str...</td>\n",
       "      <td>0.893595</td>\n",
       "      <td>0.833907</td>\n",
       "      <td>0.841184</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806420</td>\n",
       "      <td>0.081610</td>\n",
       "      <td>5</td>\n",
       "      <td>0.862478</td>\n",
       "      <td>0.873634</td>\n",
       "      <td>0.867825</td>\n",
       "      <td>0.878383</td>\n",
       "      <td>0.892835</td>\n",
       "      <td>0.875031</td>\n",
       "      <td>0.010389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.033327</td>\n",
       "      <td>0.001151</td>\n",
       "      <td>0.007782</td>\n",
       "      <td>0.000405</td>\n",
       "      <td>100</td>\n",
       "      <td>median</td>\n",
       "      <td>{'ridge__alpha': 100, 'transform__num__si__str...</td>\n",
       "      <td>0.893816</td>\n",
       "      <td>0.833685</td>\n",
       "      <td>0.841175</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806398</td>\n",
       "      <td>0.081688</td>\n",
       "      <td>6</td>\n",
       "      <td>0.862424</td>\n",
       "      <td>0.873642</td>\n",
       "      <td>0.867819</td>\n",
       "      <td>0.878376</td>\n",
       "      <td>0.892844</td>\n",
       "      <td>0.875021</td>\n",
       "      <td>0.010406</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       0.034049      0.002207         0.009171        0.001338   \n",
       "1       0.034064      0.000914         0.007842        0.000284   \n",
       "2       0.030157      0.000369         0.007588        0.000089   \n",
       "3       0.034269      0.002525         0.007771        0.000425   \n",
       "4       0.032000      0.001501         0.008202        0.000403   \n",
       "5       0.032464      0.000531         0.007599        0.000096   \n",
       "6       0.030082      0.000297         0.007481        0.000087   \n",
       "7       0.032869      0.000938         0.007679        0.000114   \n",
       "8       0.030034      0.000132         0.007594        0.000181   \n",
       "9       0.033327      0.001151         0.007782        0.000405   \n",
       "\n",
       "  param_ridge__alpha param_transform__num__si__strategy  \\\n",
       "0              0.001                               mean   \n",
       "1              0.001                             median   \n",
       "2                0.1                               mean   \n",
       "3                0.1                             median   \n",
       "4                  1                               mean   \n",
       "5                  1                             median   \n",
       "6                 10                               mean   \n",
       "7                 10                             median   \n",
       "8                100                               mean   \n",
       "9                100                             median   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'ridge__alpha': 0.001, 'transform__num__si__s...           0.901581   \n",
       "1  {'ridge__alpha': 0.001, 'transform__num__si__s...           0.901578   \n",
       "2  {'ridge__alpha': 0.1, 'transform__num__si__str...           0.899387   \n",
       "3  {'ridge__alpha': 0.1, 'transform__num__si__str...           0.899382   \n",
       "4  {'ridge__alpha': 1.0, 'transform__num__si__str...           0.894367   \n",
       "5  {'ridge__alpha': 1.0, 'transform__num__si__str...           0.894384   \n",
       "6  {'ridge__alpha': 10, 'transform__num__si__stra...           0.893760   \n",
       "7  {'ridge__alpha': 10, 'transform__num__si__stra...           0.893885   \n",
       "8  {'ridge__alpha': 100, 'transform__num__si__str...           0.893595   \n",
       "9  {'ridge__alpha': 100, 'transform__num__si__str...           0.893816   \n",
       "\n",
       "   split1_test_score  split2_test_score       ...         mean_test_score  \\\n",
       "0           0.856938           0.893413       ...                0.564308   \n",
       "1           0.856964           0.893429       ...                0.564316   \n",
       "2           0.854853           0.895557       ...                0.800789   \n",
       "3           0.854888           0.895568       ...                0.800795   \n",
       "4           0.844483           0.884532       ...                0.806715   \n",
       "5           0.844506           0.884530       ...                0.806720   \n",
       "6           0.840727           0.863183       ...                0.811317   \n",
       "7           0.840658           0.863156       ...                0.811305   \n",
       "8           0.833907           0.841184       ...                0.806420   \n",
       "9           0.833685           0.841175       ...                0.806398   \n",
       "\n",
       "   std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0        0.544383               10            0.935158            0.939936   \n",
       "1        0.544383                9            0.935158            0.939935   \n",
       "2        0.103319                8            0.934084            0.938858   \n",
       "3        0.103326                7            0.934083            0.938857   \n",
       "4        0.091847                4            0.922084            0.928361   \n",
       "5        0.091857                3            0.922086            0.928360   \n",
       "6        0.083677                1            0.897985            0.906401   \n",
       "7        0.083714                2            0.897979            0.906406   \n",
       "8        0.081610                5            0.862478            0.873634   \n",
       "9        0.081688                6            0.862424            0.873642   \n",
       "\n",
       "   split2_train_score  split3_train_score  split4_train_score  \\\n",
       "0            0.929458            0.945877            0.937442   \n",
       "1            0.929453            0.945877            0.937442   \n",
       "2            0.928206            0.944976            0.935014   \n",
       "3            0.928201            0.944977            0.935014   \n",
       "4            0.915705            0.933772            0.931898   \n",
       "5            0.915707            0.933771            0.931898   \n",
       "6            0.896868            0.909821            0.919559   \n",
       "7            0.896882            0.909821            0.919561   \n",
       "8            0.867825            0.878383            0.892835   \n",
       "9            0.867819            0.878376            0.892844   \n",
       "\n",
       "   mean_train_score  std_train_score  \n",
       "0          0.937574         0.005408  \n",
       "1          0.937573         0.005410  \n",
       "2          0.936228         0.005548  \n",
       "3          0.936227         0.005549  \n",
       "4          0.926364         0.006655  \n",
       "5          0.926364         0.006654  \n",
       "6          0.906127         0.008321  \n",
       "7          0.906130         0.008319  \n",
       "8          0.875031         0.010389  \n",
       "9          0.875021         0.010406  \n",
       "\n",
       "[10 rows x 22 columns]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(gs.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ObviousTransformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, cat_threshold=None, num_strategy='median', return_df=False):\n",
    "        self.cat_threshold = cat_threshold\n",
    "        self.num_strategy = num_strategy\n",
    "        self.return_df = return_df\n",
    "        self._columns = None\n",
    "        \n",
    "    def fit(self, X):\n",
    "        self._columns = X.columns.values\n",
    "        self._dtypes = X.dtypes.values\n",
    "        self._kinds = np.array([dt.kind for dt in X.dtypes])\n",
    "        self._column_dtypes = {}\n",
    "        is_cat = self._kinds == 'O'\n",
    "        self._column_dtypes['cat'] = self._columns[is_cat]\n",
    "        self._column_dtypes['num'] = self._columns[~is_cat]\n",
    "        self._feature_names = self._column_dtypes['num']\n",
    "        self._cat_cols = {}\n",
    "        for col in self._column_dtypes['cat']:\n",
    "            vc = X[col].value_counts()\n",
    "            if self.cat_threshold is not None:\n",
    "                vc = vc[vc > self.cat_threshold]\n",
    "            vals = vc.index.values\n",
    "            self._cat_cols[col] = vals\n",
    "            self._feature_names = np.append(self._feature_names, col + '_' + vals)\n",
    "            \n",
    "        self._total_cat_cols = sum([len(v) for col, v in self._cat_cols.items()])\n",
    "        self._num_fill = X[self._column_dtypes['num']].agg(self.num_strategy)\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X):\n",
    "        if set(self._columns) != set(X.columns):\n",
    "            raise ValueError('Passed DataFrame has different columns than fit DataFrame')\n",
    "        elif len(self._columns) != len(X.columns):\n",
    "            raise ValueError('Passed DataFrame has different number of columns than fit DataFrame')\n",
    "            \n",
    "        X_num = X[self._column_dtypes['num']].fillna(self._num_fill)\n",
    "        X_num = (X_num - X_num.mean()) / X_num.std()\n",
    "        X_num = X_num.values\n",
    "        X_cat = np.empty((len(X), self._total_cat_cols), dtype='int')\n",
    "        i = 0\n",
    "        for col in self._column_dtypes['cat']:\n",
    "            vals = self._cat_cols[col]\n",
    "            for val in vals:\n",
    "                X_cat[:, i] = X[col] == val\n",
    "                i += 1\n",
    "                \n",
    "        data = np.column_stack((X_num, X_cat))\n",
    "        if self.return_df:\n",
    "            return pd.DataFrame(data=data, columns=self._feature_names)\n",
    "        else:\n",
    "            return data\n",
    "    \n",
    "    def fit_transform(self, X):\n",
    "        return self.fit(X).transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "ot = ObviousTransformer(cat_threshold=0, return_df=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ot.fit_transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 289)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "ridge = Ridge(alpha=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=100, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge.fit(X_train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8702432916493581"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge.score(X_train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9079027436742987"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "lr.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-7.480134477170103e+19"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(365, 202)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8293505911080119"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(ridge, X, y, cv=kf).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.9144976430754385e+20"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(lr, X_train, y, cv=kf).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8961668139404931"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(X_train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 202)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Id', 'MSSubClass', 'LotFrontage', 'LotArea', 'OverallQual',\n",
       "       'OverallCond', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea',\n",
       "       'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF',\n",
       "       '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'BsmtFullBath',\n",
       "       'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr',\n",
       "       'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces', 'GarageYrBlt',\n",
       "       'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF',\n",
       "       'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal',\n",
       "       'MoSold', 'YrSold', 'MSZoning_RL', 'MSZoning_RM', 'MSZoning_FV',\n",
       "       'MSZoning_RH', 'Street_Pave', 'Alley_Grvl', 'Alley_Pave',\n",
       "       'LotShape_Reg', 'LotShape_IR1', 'LotShape_IR2', 'LandContour_Lvl',\n",
       "       'LandContour_Bnk', 'LandContour_HLS', 'LandContour_Low',\n",
       "       'Utilities_AllPub', 'LotConfig_Inside', 'LotConfig_Corner',\n",
       "       'LotConfig_CulDSac', 'LotConfig_FR2', 'LandSlope_Gtl',\n",
       "       'LandSlope_Mod', 'Neighborhood_NAmes', 'Neighborhood_CollgCr',\n",
       "       'Neighborhood_OldTown', 'Neighborhood_Edwards',\n",
       "       'Neighborhood_Somerst', 'Neighborhood_Gilbert',\n",
       "       'Neighborhood_NridgHt', 'Neighborhood_Sawyer',\n",
       "       'Neighborhood_NWAmes', 'Neighborhood_SawyerW',\n",
       "       'Neighborhood_BrkSide', 'Neighborhood_Crawfor',\n",
       "       'Neighborhood_Mitchel', 'Neighborhood_NoRidge',\n",
       "       'Neighborhood_Timber', 'Neighborhood_IDOTRR',\n",
       "       'Neighborhood_ClearCr', 'Neighborhood_SWISU',\n",
       "       'Neighborhood_StoneBr', 'Neighborhood_MeadowV',\n",
       "       'Neighborhood_Blmngtn', 'Neighborhood_BrDale', 'Condition1_Norm',\n",
       "       'Condition1_Feedr', 'Condition1_Artery', 'Condition1_RRAn',\n",
       "       'Condition1_PosN', 'Condition2_Norm', 'BldgType_1Fam',\n",
       "       'BldgType_TwnhsE', 'BldgType_Duplex', 'BldgType_Twnhs',\n",
       "       'BldgType_2fmCon', 'HouseStyle_1Story', 'HouseStyle_2Story',\n",
       "       'HouseStyle_1.5Fin', 'HouseStyle_SLvl', 'HouseStyle_SFoyer',\n",
       "       'RoofStyle_Gable', 'RoofStyle_Hip', 'RoofMatl_CompShg',\n",
       "       'Exterior1st_VinylSd', 'Exterior1st_HdBoard',\n",
       "       'Exterior1st_MetalSd', 'Exterior1st_Wd Sdng',\n",
       "       'Exterior1st_Plywood', 'Exterior1st_CemntBd',\n",
       "       'Exterior1st_BrkFace', 'Exterior1st_WdShing', 'Exterior1st_Stucco',\n",
       "       'Exterior1st_AsbShng', 'Exterior2nd_VinylSd',\n",
       "       'Exterior2nd_MetalSd', 'Exterior2nd_HdBoard',\n",
       "       'Exterior2nd_Wd Sdng', 'Exterior2nd_Plywood',\n",
       "       'Exterior2nd_CmentBd', 'Exterior2nd_Wd Shng', 'Exterior2nd_Stucco',\n",
       "       'Exterior2nd_BrkFace', 'Exterior2nd_AsbShng', 'MasVnrType_None',\n",
       "       'MasVnrType_BrkFace', 'MasVnrType_Stone', 'ExterQual_TA',\n",
       "       'ExterQual_Gd', 'ExterQual_Ex', 'ExterCond_TA', 'ExterCond_Gd',\n",
       "       'ExterCond_Fa', 'Foundation_PConc', 'Foundation_CBlock',\n",
       "       'Foundation_BrkTil', 'Foundation_Slab', 'BsmtQual_TA',\n",
       "       'BsmtQual_Gd', 'BsmtQual_Ex', 'BsmtQual_Fa', 'BsmtCond_TA',\n",
       "       'BsmtCond_Gd', 'BsmtCond_Fa', 'BsmtExposure_No', 'BsmtExposure_Av',\n",
       "       'BsmtExposure_Gd', 'BsmtExposure_Mn', 'BsmtFinType1_Unf',\n",
       "       'BsmtFinType1_GLQ', 'BsmtFinType1_ALQ', 'BsmtFinType1_BLQ',\n",
       "       'BsmtFinType1_Rec', 'BsmtFinType1_LwQ', 'BsmtFinType2_Unf',\n",
       "       'BsmtFinType2_Rec', 'BsmtFinType2_LwQ', 'BsmtFinType2_BLQ',\n",
       "       'BsmtFinType2_ALQ', 'Heating_GasA', 'Heating_GasW', 'HeatingQC_Ex',\n",
       "       'HeatingQC_TA', 'HeatingQC_Gd', 'HeatingQC_Fa', 'CentralAir_Y',\n",
       "       'CentralAir_N', 'Electrical_SBrkr', 'Electrical_FuseA',\n",
       "       'Electrical_FuseF', 'KitchenQual_TA', 'KitchenQual_Gd',\n",
       "       'KitchenQual_Ex', 'KitchenQual_Fa', 'Functional_Typ',\n",
       "       'Functional_Min2', 'Functional_Min1', 'FireplaceQu_Gd',\n",
       "       'FireplaceQu_TA', 'FireplaceQu_Fa', 'FireplaceQu_Ex',\n",
       "       'FireplaceQu_Po', 'GarageType_Attchd', 'GarageType_Detchd',\n",
       "       'GarageType_BuiltIn', 'GarageType_Basment', 'GarageFinish_Unf',\n",
       "       'GarageFinish_RFn', 'GarageFinish_Fin', 'GarageQual_TA',\n",
       "       'GarageQual_Fa', 'GarageCond_TA', 'GarageCond_Fa', 'PavedDrive_Y',\n",
       "       'PavedDrive_N', 'PavedDrive_P', 'Fence_MnPrv', 'Fence_GdPrv',\n",
       "       'Fence_GdWo', 'MiscFeature_Shed', 'SaleType_WD', 'SaleType_New',\n",
       "       'SaleType_COD', 'SaleCondition_Normal', 'SaleCondition_Partial',\n",
       "       'SaleCondition_Abnorml', 'SaleCondition_Family'], dtype=object)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ot._feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
